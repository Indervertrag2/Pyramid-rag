version: '3.9'

services:
  # PostgreSQL with pgvector
  postgres:
    image: ankane/pgvector:v0.5.1
    container_name: pyramid-postgres
    environment:
      POSTGRES_DB: pyramid_rag
      POSTGRES_USER: pyramid
      POSTGRES_PASSWORD: pyramid_secure_pass
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "15432:5432"
    networks:
      - pyramid-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pyramid -d pyramid_rag"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: pyramid-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "16379:6379"
    networks:
      - pyramid-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend API (Minimal)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.minimal
    container_name: pyramid-backend
    environment:
      DATABASE_URL: postgresql://pyramid:pyramid_secure_pass@postgres:5432/pyramid_rag
      REDIS_URL: redis://redis:6379/0
    volumes:
      - ./backend:/app
      - document_storage:/app/data
    ports:
      - "18000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mcp:
        condition: service_healthy
    networks:
      - pyramid-network
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # MCP Server for AI orchestration
  mcp:
    build:
      context: ./backend
      dockerfile: Dockerfile.mcp
    container_name: pyramid-mcp
    ports:
      - "18001:8001"
    depends_on:
      - ollama
    networks:
      - pyramid-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Ollama for LLM
  ollama:
    image: ollama/ollama:latest
    container_name: pyramid-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - pyramid-network
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_GPU=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Simple Frontend
  frontend:
    image: node:20-alpine
    container_name: pyramid-frontend
    working_dir: /app
    volumes:
      - ./frontend:/app
    ports:
      - "3002:3000"
    networks:
      - pyramid-network
    command: sh -c "npm install --legacy-peer-deps && npm run dev -- --host 0.0.0.0"
    environment:
      - VITE_API_URL=http://localhost:18000

  # Nginx (Disabled - not needed for development)
  # nginx:
  #   image: nginx:alpine
  #   container_name: pyramid-nginx
  #   volumes:
  #     - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
  #   ports:
  #     - "8080:80"
  #   depends_on:
  #     - backend
  #     - frontend
  #   networks:
  #     - pyramid-network

networks:
  pyramid-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  document_storage:
    driver: local